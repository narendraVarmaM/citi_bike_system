{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a47fbd-54a0-4303-9930-bec21ee4af13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7b02256-6f46-482a-aca7-58f371706d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62dbc040-c179-4893-8bca-7c556d757394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download raw data from 2024 to 2025\n",
      "File already exists for 2024-01.\n",
      "Loading data for 2024-01...\n",
      "Total records: 1,881,640\n",
      "Valid records: 57,196\n",
      "Records dropped: 1,824,444 (96.96%)\n",
      "Successfully processed data for 2024-01.\n",
      "File already exists for 2024-02.\n",
      "Loading data for 2024-02...\n",
      "Total records: 2,115,518\n",
      "Valid records: 68,438\n",
      "Records dropped: 2,047,080 (96.76%)\n",
      "Successfully processed data for 2024-02.\n",
      "File already exists for 2024-03.\n",
      "Loading data for 2024-03...\n",
      "Total records: 2,655,667\n",
      "Valid records: 80,317\n",
      "Records dropped: 2,575,350 (96.98%)\n",
      "Successfully processed data for 2024-03.\n",
      "File already exists for 2024-04.\n",
      "Loading data for 2024-04...\n",
      "Total records: 3,208,493\n",
      "Valid records: 98,794\n",
      "Records dropped: 3,109,699 (96.92%)\n",
      "Successfully processed data for 2024-04.\n",
      "File already exists for 2024-05.\n",
      "Loading data for 2024-05...\n",
      "Total records: 4,219,327\n",
      "Valid records: 124,424\n",
      "Records dropped: 4,094,903 (97.05%)\n",
      "Successfully processed data for 2024-05.\n",
      "File already exists for 2024-06.\n",
      "Loading data for 2024-06...\n",
      "Total records: 4,767,659\n",
      "Valid records: 139,068\n",
      "Records dropped: 4,628,591 (97.08%)\n",
      "Successfully processed data for 2024-06.\n",
      "File already exists for 2024-07.\n",
      "Loading data for 2024-07...\n",
      "Total records: 4,706,150\n",
      "Valid records: 139,111\n",
      "Records dropped: 4,567,039 (97.04%)\n",
      "Successfully processed data for 2024-07.\n",
      "File already exists for 2024-08.\n",
      "Loading data for 2024-08...\n",
      "Total records: 4,586,537\n",
      "Valid records: 136,344\n",
      "Records dropped: 4,450,193 (97.03%)\n",
      "Successfully processed data for 2024-08.\n",
      "File already exists for 2024-09.\n",
      "Loading data for 2024-09...\n",
      "Total records: 4,979,857\n",
      "Valid records: 150,776\n",
      "Records dropped: 4,829,081 (96.97%)\n",
      "Successfully processed data for 2024-09.\n",
      "File already exists for 2024-10.\n",
      "Loading data for 2024-10...\n",
      "Total records: 5,131,292\n",
      "Valid records: 160,539\n",
      "Records dropped: 4,970,753 (96.87%)\n",
      "Successfully processed data for 2024-10.\n",
      "File already exists for 2024-11.\n",
      "Loading data for 2024-11...\n",
      "Total records: 3,696,124\n",
      "Valid records: 119,260\n",
      "Records dropped: 3,576,864 (96.77%)\n",
      "Successfully processed data for 2024-11.\n",
      "File already exists for 2024-12.\n",
      "Loading data for 2024-12...\n",
      "Total records: 2,302,229\n",
      "Valid records: 74,450\n",
      "Records dropped: 2,227,779 (96.77%)\n",
      "Successfully processed data for 2024-12.\n",
      "Combining all monthly data...\n",
      "Data loading and processing complete!\n",
      "Data loading complete.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from src.data_utils import load_and_process_taxi_data\n",
    "\n",
    "from_year = 2024\n",
    "# to_year = datetime.now().year\n",
    "to_year = 2025\n",
    "print(f\"Download raw data from {from_year} to {to_year}\")\n",
    "\n",
    "rides = pd.DataFrame()\n",
    "chunks = []\n",
    "for year in range(from_year, to_year+1):\n",
    "\n",
    "    rides_one_year = load_and_process_taxi_data(year)\n",
    "\n",
    "    chunks.append(rides_one_year)\n",
    "    break\n",
    "\n",
    "# Concatenate all chunks at the end\n",
    "rides = pd.concat(chunks, ignore_index=True)\n",
    "print(\"Data loading complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce5589a2-9316-4dac-ba2e-e9a8a4789241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>started_at</th>\n",
       "      <th>pickup_location_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-22 12:18:53.512</td>\n",
       "      <td>5779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-13 18:52:26.496</td>\n",
       "      <td>5779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-31 16:59:37.612</td>\n",
       "      <td>5779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-04 07:17:28.970</td>\n",
       "      <td>5779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-12 09:06:28.532</td>\n",
       "      <td>5779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348712</th>\n",
       "      <td>2024-12-15 15:05:05.351</td>\n",
       "      <td>5905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348713</th>\n",
       "      <td>2024-12-30 09:08:31.156</td>\n",
       "      <td>5905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348714</th>\n",
       "      <td>2024-12-30 16:25:25.701</td>\n",
       "      <td>5788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348715</th>\n",
       "      <td>2024-12-30 16:47:39.666</td>\n",
       "      <td>5788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348716</th>\n",
       "      <td>2024-12-20 17:32:14.795</td>\n",
       "      <td>5788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1348717 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     started_at  pickup_location_id\n",
       "0       2024-01-22 12:18:53.512                5779\n",
       "1       2024-01-13 18:52:26.496                5779\n",
       "2       2024-01-31 16:59:37.612                5779\n",
       "3       2024-01-04 07:17:28.970                5779\n",
       "4       2024-01-12 09:06:28.532                5779\n",
       "...                         ...                 ...\n",
       "1348712 2024-12-15 15:05:05.351                5905\n",
       "1348713 2024-12-30 09:08:31.156                5905\n",
       "1348714 2024-12-30 16:25:25.701                5788\n",
       "1348715 2024-12-30 16:47:39.666                5788\n",
       "1348716 2024-12-20 17:32:14.795                5788\n",
       "\n",
       "[1348717 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59f47e90-0fcb-4b7a-80d0-a68c979f9ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1348717, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rides.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5259f4bd-65ce-43dc-b487-09ee12d964bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils import transform_raw_data_into_ts_data\n",
    "\n",
    "ts_data = transform_raw_data_into_ts_data(rides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59252b5f-17fc-4207-a1c4-6bebd49233ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10985, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92402d0c-dacd-4039-ba40-caf7eeafe8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10985 entries, 0 to 10984\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   pickup_hour         10985 non-null  datetime64[ns]\n",
      " 1   pickup_location_id  10985 non-null  int16         \n",
      " 2   rides               10985 non-null  int16         \n",
      "dtypes: datetime64[ns](1), int16(2)\n",
      "memory usage: 128.9 KB\n"
     ]
    }
   ],
   "source": [
    "ts_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3804e864-fcde-41f4-bf92-5c0e8e90aa0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-31 20:00:00</td>\n",
       "      <td>5626</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>5626</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01 04:00:00</td>\n",
       "      <td>5626</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01 08:00:00</td>\n",
       "      <td>5626</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01 12:00:00</td>\n",
       "      <td>5626</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10980</th>\n",
       "      <td>2024-12-31 04:00:00</td>\n",
       "      <td>6072</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10981</th>\n",
       "      <td>2024-12-31 08:00:00</td>\n",
       "      <td>6072</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10982</th>\n",
       "      <td>2024-12-31 12:00:00</td>\n",
       "      <td>6072</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10983</th>\n",
       "      <td>2024-12-31 16:00:00</td>\n",
       "      <td>6072</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10984</th>\n",
       "      <td>2024-12-31 20:00:00</td>\n",
       "      <td>6072</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10985 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              pickup_hour  pickup_location_id  rides\n",
       "0     2023-12-31 20:00:00                5626      4\n",
       "1     2024-01-01 00:00:00                5626     42\n",
       "2     2024-01-01 04:00:00                5626      9\n",
       "3     2024-01-01 08:00:00                5626     40\n",
       "4     2024-01-01 12:00:00                5626     76\n",
       "...                   ...                 ...    ...\n",
       "10980 2024-12-31 04:00:00                6072      8\n",
       "10981 2024-12-31 08:00:00                6072     80\n",
       "10982 2024-12-31 12:00:00                6072    105\n",
       "10983 2024-12-31 16:00:00                6072     63\n",
       "10984 2024-12-31 20:00:00                6072     18\n",
       "\n",
       "[10985 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8949a20a-f5da-45ff-990f-d789d234cdf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-11 05:32:58,927 INFO: Initializing external client\n",
      "2025-05-11 05:32:58,928 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-11 05:32:59,983 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1214695\n",
      "Successfully connected to Hopsworks project: sp25_taxi_nmuppala\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "api_key = os.getenv('HOPSWORKS_API_KEY')  \n",
    "project_name = os.getenv('HOPSWORKS_PROJECT_NAME')  \n",
    "\n",
    "# pip install confluent-kafka\n",
    "# Initialize connection to Hopsworks  \n",
    "project = hopsworks.login(  \n",
    "    api_key_value=api_key,  \n",
    "    project=project_name  \n",
    ")  \n",
    "print(f\"Successfully connected to Hopsworks project: {project_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae5a3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4294fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_GROUP_NAME = \"citibike_hourly_features\"\n",
    "FEATURE_GROUP_VERSION = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f885dc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group = feature_store.get_or_create_feature_group(\n",
    "    name=FEATURE_GROUP_NAME,\n",
    "    version=FEATURE_GROUP_VERSION,\n",
    "    primary_key=['pickup_location_id', 'pickup_hour'],\n",
    "    event_time=['pickup_hour']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e05e91ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1214695/fs/1202330/fg/1458598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 10985/10985 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: citibike_hourly_features_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1214695/jobs/named/citibike_hourly_features_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('citibike_hourly_features_1_offline_fg_materialization', 'SPARK'), None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_group.insert(ts_data, write_options={\"wait_for_job\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c360d4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature group created successfully!\n"
     ]
    }
   ],
   "source": [
    "from hsfs.feature_group import FeatureGroup\n",
    "\n",
    "feature_store = project.get_feature_store()\n",
    "\n",
    "# Create the feature group\n",
    "feature_group = feature_store.create_feature_group(\n",
    "    name=\"time_series_hourly_feature_group\",\n",
    "    version=1,\n",
    "    description=\"Feature group for hourly time series data\",\n",
    "    primary_key=[\"timestamp\"],  # Adjust primary key according to your dataset\n",
    "    online_enabled=True\n",
    ")\n",
    "print(\"Feature group created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fbf8a538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature group created with supported primary key for online serving.\n"
     ]
    }
   ],
   "source": [
    "feature_group = feature_store.create_feature_group(\n",
    "    name=\"time_series_hourly_feature_group\",\n",
    "    version=1,\n",
    "    description=\"Feature group of hourly time series data\",  # Use the new 'id' column as the primary key\n",
    "    online_enabled=True   # Enable online serving if needed\n",
    ")\n",
    "print(\"Feature group created with supported primary key for online serving.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28a35b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data['pickup_hour'] = pd.to_datetime(ts_data['pickup_hour'])\n",
    "ts_data['pickup_location_id'] = ts_data['pickup_location_id'].astype(int)\n",
    "ts_data['rides'] = ts_data['rides'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23970890",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_GROUP_NAME = \"time_series_hourly_feature_group\"\n",
    "FEATURE_GROUP_VERSION = 1\n",
    "\n",
    "feature_group = feature_store.get_or_create_feature_group(\n",
    "    name=FEATURE_GROUP_NAME,\n",
    "    version=FEATURE_GROUP_VERSION,\n",
    "    description=\"Time series data at hourly frequency\",\n",
    "    primary_key=['pickup_location_id', 'pickup_hour'],\n",
    "    event_time=['pickup_hour']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2a1268d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1214695/fs/1202330/fg/1401999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 2277600/2277600 | Elapsed Time: 00:55 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: time_series_hourly_feature_group_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1214695/jobs/named/time_series_hourly_feature_group_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('time_series_hourly_feature_group_1_offline_fg_materialization', 'SPARK'),\n",
       " None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data.rename(columns={\n",
    "    \"pickup_hour\": 'pickup_hour',\n",
    "    \"pickup_location_id\": 'pickup_location_id',\n",
    "    \"rides\": 'rides'\n",
    "}, inplace=True)\n",
    "\n",
    "ts_data_selected = ts_data[['pickup_hour', 'pickup_location_id', 'rides']]\n",
    "\n",
    "feature_group.insert(ts_data_selected, write_options={\"wait_for_job\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e23ce4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame size: 857.47 MB\n"
     ]
    }
   ],
   "source": [
    "df_memory_mb = rides.memory_usage(deep=True).sum() / (1024 * 1024)  \n",
    "print(f\"DataFrame size: {df_memory_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa5badd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2277600 entries, 0 to 2277599\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   pickup_hour         datetime64[ns]\n",
      " 1   pickup_location_id  int64         \n",
      " 2   rides               int64         \n",
      "dtypes: datetime64[ns](1), int64(2)\n",
      "memory usage: 52.1 MB\n"
     ]
    }
   ],
   "source": [
    "ts_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "348b1a4b-6141-4078-bc9f-e9e3a750a0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d54682e-b7d3-49fc-86bd-65b1b06206bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_GROUP_NAME = \"time_series_hourly_feature_group\"\n",
    "FEATURE_GROUP_VERSION = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f7dd4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature group created successfully!\n"
     ]
    }
   ],
   "source": [
    "from hsfs.feature_group import FeatureGroup\n",
    "\n",
    "# Create the feature group\n",
    "feature_group = feature_store.create_feature_group(\n",
    "    name=\"time_series_hourly_feature_group\",\n",
    "    version=1,\n",
    "    description=\"Feature group for hourly time series data\",\n",
    "    primary_key=[\"timestamp\"],  # Adjust primary key according to your dataset\n",
    "    online_enabled=True\n",
    ")\n",
    "print(\"Feature group created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bb71b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature group created with supported primary key for online serving.\n"
     ]
    }
   ],
   "source": [
    "feature_group = feature_store.create_feature_group(\n",
    "    name=\"time_series_hourly_feature_group\",\n",
    "    version=1,\n",
    "    description=\"Feature group for hourly time series data\",  # Use the new 'id' column as the primary key\n",
    "    online_enabled=True   # Enable online serving if needed\n",
    ")\n",
    "print(\"Feature group created with supported primary key for online serving.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08928326",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.rename(columns={\n",
    "    'pickup_hour': 'pickup_hour',\n",
    "    'pickup_location_id': 'pickup_location_id',\n",
    "    'rides': 'rides'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f537e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data['pickup_hour'] = pd.to_datetime(ts_data['pickup_hour'])\n",
    "ts_data['pickup_location_id'] = ts_data['pickup_location_id'].astype(int)\n",
    "ts_data['rides'] = ts_data['rides'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be1383db",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_GROUP_NAME = \"time_series_hourly_feature_group\"\n",
    "FEATURE_GROUP_VERSION = 1\n",
    "\n",
    "feature_group = feature_store.get_or_create_feature_group(\n",
    "    name=FEATURE_GROUP_NAME,\n",
    "    version=FEATURE_GROUP_VERSION,\n",
    "    description=\"Time series data at hourly frequency\",\n",
    "    primary_key=['pickup_location_id', 'pickup_hour'],\n",
    "    event_time=['pickup_hour']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46a7333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data = ts_data.rename(columns={\n",
    "    \"pickup_hour\": \"timestamp\",\n",
    "    \"rides\": \"ride_count\",\n",
    "    \"pickup_location_id\": \"pickup_location\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46ee5a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1214695/fs/1202330/fg/1401992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 2277600/2277600 | Elapsed Time: 00:55 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: time_series_hourly_feature_group_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1214695/jobs/named/time_series_hourly_feature_group_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('time_series_hourly_feature_group_1_offline_fg_materialization', 'SPARK'),\n",
       " None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the columns\n",
    "ts_data.rename(columns={\n",
    "    'timestamp': 'pickup_hour',\n",
    "    'pickup_location': 'pickup_location_id',\n",
    "    'ride_count': 'rides'\n",
    "}, inplace=True)\n",
    "\n",
    "# Select only the required columns\n",
    "ts_data_selected = ts_data[['pickup_hour', 'pickup_location_id', 'rides']]\n",
    "\n",
    "# Insert the selected columns into the feature group\n",
    "feature_group.insert(ts_data_selected, write_options={\"wait_for_job\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f0ced7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame size: 857.47 MB\n"
     ]
    }
   ],
   "source": [
    "df_memory_mb = rides.memory_usage(deep=True).sum() / (1024 * 1024)  \n",
    "print(f\"DataFrame size: {df_memory_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3fa0df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2277600 entries, 0 to 2277599\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   pickup_hour         datetime64[ns]\n",
      " 1   pickup_location_id  int64         \n",
      " 2   rides               int64         \n",
      "dtypes: datetime64[ns](1), int64(2)\n",
      "memory usage: 52.1 MB\n"
     ]
    }
   ],
   "source": [
    "ts_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906317bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f47e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8d90ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                 pickup_hour  pickup_location_id  rides      pickup_hour_str\n",
       "0       2023-01-01 00:00:00                   2      0  2023-01-01 00:00:00\n",
       "1       2023-01-01 01:00:00                   2      0  2023-01-01 01:00:00\n",
       "2       2023-01-01 02:00:00                   2      0  2023-01-01 02:00:00\n",
       "3       2023-01-01 03:00:00                   2      0  2023-01-01 03:00:00\n",
       "4       2023-01-01 04:00:00                   2      0  2023-01-01 04:00:00\n",
       "...                     ...                 ...    ...                  ...\n",
       "2277595 2023-12-31 19:00:00                 263    188  2023-12-31 19:00:00\n",
       "2277596 2023-12-31 20:00:00                 263    198  2023-12-31 20:00:00\n",
       "2277597 2023-12-31 21:00:00                 263    232  2023-12-31 21:00:00\n",
       "2277598 2023-12-31 22:00:00                 263    160  2023-12-31 22:00:00\n",
       "2277599 2023-12-31 23:00:00                 263     95  2023-12-31 23:00:00\n",
       "\n",
       "[2277600 rows x 4 columns]>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data['pickup_hour_str'] = ts_data['pickup_hour'].dt.strftime('%Y-%m-%d %H:00:00')\n",
    "ts_data['pickup_hour'] = pd.to_datetime(ts_data['pickup_hour'])\n",
    "\n",
    "\n",
    "ts_data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eeab5c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10985 entries, 0 to 10984\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   pickup_hour         10985 non-null  datetime64[ns]\n",
      " 1   pickup_location_id  10985 non-null  int16         \n",
      " 2   rides               10985 non-null  int16         \n",
      "dtypes: datetime64[ns](1), int16(2)\n",
      "memory usage: 128.9 KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ts_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f292eed-c4a1-4d3a-8ee9-daa7bb1fea5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group = feature_store.get_or_create_feature_group(\n",
    "    name=\"citibike_hourly_features\",\n",
    "    version=1,\n",
    "    description=\"Feature group for ride data\",\n",
    "    primary_key=[\"pickup_hour\", \"pickup_location_id\"],\n",
    "    event_time=\"pickup_hour\",\n",
    "    online_enabled=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bda251e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickup_hour           datetime64[ns]\n",
      "pickup_location_id             int16\n",
      "rides                          int16\n",
      "dtype: object\n",
      "Index(['pickup_hour', 'pickup_location_id', 'rides'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Feature('pickup_hour', 'timestamp', None, True, False, None, None, 1458598),\n",
       " Feature('pickup_location_id', 'int', None, True, False, None, None, 1458598),\n",
       " Feature('rides', 'int', None, False, False, None, None, 1458598)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ts_data.dtypes)\n",
    "print(ts_data.columns)\n",
    "\n",
    "feature_group.schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec573dd2-3125-4d2f-93a9-975bedfe739f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 10985/10985 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: citibike_hourly_features_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1214695/jobs/named/citibike_hourly_features_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('citibike_hourly_features_1_offline_fg_materialization', 'SPARK'), None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_group.insert(ts_data, write_options={\"wait_for_job\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9ff98cc-31f4-47b4-a43c-fe731760af71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame size: 30.87 MB\n"
     ]
    }
   ],
   "source": [
    "df_memory_mb = rides.memory_usage(deep=True).sum() / (1024 * 1024)  \n",
    "print(f\"DataFrame size: {df_memory_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be636b4b-4bd5-469d-8cc7-b09e1de29ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10985 entries, 0 to 10984\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   pickup_hour         10985 non-null  datetime64[ns]\n",
      " 1   pickup_location_id  10985 non-null  int16         \n",
      " 2   rides               10985 non-null  int16         \n",
      "dtypes: datetime64[ns](1), int16(2)\n",
      "memory usage: 128.9 KB\n"
     ]
    }
   ],
   "source": [
    "ts_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d5f696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_proj_cda500_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
